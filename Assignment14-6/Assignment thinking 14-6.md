1、XGBoost与GBDT的区别是什么？	
XGBoost算法对特点是：
XGBoost将树模型的复杂度加入到正则项中，从而避免过拟合，泛化性能好
损失函数是用泰勒展开式展开的，用到了一阶导和二阶导，可以加快优化速度
在寻找最佳分割点时，采用近似贪心算法，用来加速计算
不仅支持CART作为基分类器，还支持线性分类器，在使用线性分类器的时候可以使用L1，L2正则化
支持并行计算，XGBoost的并行是基于特征计算的并行，将特征列排序后以block的形式存储在内存中，在后面的迭代中重复使用这个结构。在进行节点分裂时，计算每个特征的增益，选择增益最大的特征作为分割节点，各个特征的增益计算可以使用多线程并行
以上xgboost的特点也是GBDT与其的区别，xgb是gbdt的改良版，拥有更快的收敛速度和准确率，两者对高维的特征都比较敏感，结果波动较大。
优点：速度快、效果好、能处理大规模数据、支持自定义损失函数等
缺点：算法参数过多，调参复杂，不适合处理超高维特征数据


2、举一个你之前做过的预测例子（用的什么模型，解决什么问题，比如我用LR模型，对员工离职进行了预测，效果如何... 请分享到课程微信群中）	
车辆轨迹预测与广州塔客流量预测，分别用了w2c与LSTM以及lightgbm模型，分别拟合车辆轨迹抓拍点的时空变化、趋势习惯以及使用lightgbm对广州塔景区对客流量引入天气、时间等特征后对预测，效果都已经达到了上线对效果，轨迹预测是达到70多对准确率，客流量预测达到了比较小对mse误差值。


3、请你思考，在你的工作中，需要构建哪些特征（比如用户画像，item特征...），这些特征都包括哪些维度（鼓励分享到微信群中，进行交流）		
在工作中接触过轨迹数据特征，人员画像特征，主要是黑名单人员和重点关注人员。