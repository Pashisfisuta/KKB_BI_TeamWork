{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取数据\n",
    "train_data = pd.read_csv('train_nn.csv', sep=' ')\n",
    "test_data = pd.read_csv('test_nn.csv', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.columns\n",
    "feature_cols = [col for col in X if col not in ['price','SaleID']]\n",
    "## 提前特征列，标签列构造训练样本和测试样本\n",
    "X_train = train_data[feature_cols]\n",
    "X_test = test_data[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(X_train)\n",
    "y = np.array(train_data['price'])\n",
    "x_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"callbacks\")\n",
    "output_model_file = os.path.join(logdir,\"model.h5\")  # 输出的model文件\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(logdir),\n",
    "    keras.callbacks.ModelCheckpoint(output_model_file, save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "  2/235 [..............................] - ETA: 10s - loss: 5864.8633 - mae: 5851.9321WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0194s vs `on_train_batch_end` time: 0.0704s). Check your callbacks.\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 3480.5056 - mae: 3462.7534 - val_loss: 1377.3254 - val_mae: 1342.5182\n",
      "Epoch 2/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 1211.7534 - mae: 1171.1053 - val_loss: 1109.3164 - val_mae: 1065.7935\n",
      "Epoch 3/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 1053.0853 - mae: 1008.1841 - val_loss: 989.4257 - val_mae: 943.0027\n",
      "Epoch 4/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 959.3339 - mae: 912.2347 - val_loss: 916.9647 - val_mae: 869.6070\n",
      "Epoch 5/500\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 899.9656 - mae: 852.2472 - val_loss: 881.4904 - val_mae: 833.6614\n",
      "Epoch 6/500\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 858.2123 - mae: 810.2964 - val_loss: 833.7025 - val_mae: 786.0568\n",
      "Epoch 7/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 821.3643 - mae: 773.6117 - val_loss: 827.4697 - val_mae: 779.4424\n",
      "Epoch 8/500\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 797.0390 - mae: 748.8141 - val_loss: 785.2661 - val_mae: 736.9891\n",
      "Epoch 9/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 763.5891 - mae: 714.8790 - val_loss: 754.2371 - val_mae: 705.0255\n",
      "Epoch 10/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 750.8037 - mae: 701.3790 - val_loss: 731.2899 - val_mae: 681.4446\n",
      "Epoch 11/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 731.6774 - mae: 681.7035 - val_loss: 726.5151 - val_mae: 676.1473\n",
      "Epoch 12/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 713.4617 - mae: 663.0621 - val_loss: 704.9135 - val_mae: 653.9839\n",
      "Epoch 13/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 701.0623 - mae: 650.0398 - val_loss: 704.4483 - val_mae: 653.2520\n",
      "Epoch 14/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 694.4697 - mae: 643.1251 - val_loss: 690.0056 - val_mae: 638.4366\n",
      "Epoch 15/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 685.9289 - mae: 634.1086 - val_loss: 678.1173 - val_mae: 626.4588\n",
      "Epoch 16/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 680.8158 - mae: 628.9196 - val_loss: 695.2109 - val_mae: 643.0126\n",
      "Epoch 17/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 675.6827 - mae: 623.4982 - val_loss: 661.9227 - val_mae: 609.4511\n",
      "Epoch 18/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 672.0285 - mae: 619.4772 - val_loss: 706.2182 - val_mae: 653.8626\n",
      "Epoch 19/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 662.0557 - mae: 609.6698 - val_loss: 655.5612 - val_mae: 602.9027\n",
      "Epoch 20/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 657.9716 - mae: 605.2352 - val_loss: 650.6014 - val_mae: 598.0390\n",
      "Epoch 21/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 649.8724 - mae: 597.1468 - val_loss: 645.5646 - val_mae: 592.8006\n",
      "Epoch 22/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 648.1627 - mae: 595.4692 - val_loss: 647.1675 - val_mae: 594.2855\n",
      "Epoch 23/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 651.9705 - mae: 599.0546 - val_loss: 642.9254 - val_mae: 590.2856\n",
      "Epoch 24/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 637.1561 - mae: 584.5389 - val_loss: 706.2352 - val_mae: 653.4027\n",
      "Epoch 25/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 638.6277 - mae: 585.8850 - val_loss: 647.2512 - val_mae: 594.4559\n",
      "Epoch 26/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 634.5815 - mae: 581.9081 - val_loss: 633.0505 - val_mae: 580.2593\n",
      "Epoch 27/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 630.3866 - mae: 577.6321 - val_loss: 621.4155 - val_mae: 568.8813\n",
      "Epoch 28/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 627.5814 - mae: 574.8970 - val_loss: 661.0057 - val_mae: 608.3269\n",
      "Epoch 29/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 628.5150 - mae: 575.7814 - val_loss: 633.8359 - val_mae: 581.2137\n",
      "Epoch 30/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 620.8414 - mae: 568.1656 - val_loss: 614.6181 - val_mae: 561.9805\n",
      "Epoch 31/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 620.8809 - mae: 568.4562 - val_loss: 625.4919 - val_mae: 573.0826\n",
      "Epoch 32/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 619.0295 - mae: 566.4370 - val_loss: 628.4993 - val_mae: 575.9215\n",
      "Epoch 33/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 615.3333 - mae: 562.8300 - val_loss: 668.0066 - val_mae: 615.5196\n",
      "Epoch 34/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 615.6742 - mae: 563.1896 - val_loss: 614.7991 - val_mae: 562.3811\n",
      "Epoch 35/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 608.9308 - mae: 556.5739 - val_loss: 603.1920 - val_mae: 550.7374\n",
      "Epoch 36/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 607.6003 - mae: 555.1849 - val_loss: 598.2399 - val_mae: 545.8127\n",
      "Epoch 37/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 602.6805 - mae: 550.2558 - val_loss: 599.4653 - val_mae: 547.3987\n",
      "Epoch 38/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 604.0364 - mae: 551.9272 - val_loss: 649.8027 - val_mae: 597.7117\n",
      "Epoch 39/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 603.7687 - mae: 551.7151 - val_loss: 596.4959 - val_mae: 544.5128\n",
      "Epoch 40/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 596.4218 - mae: 544.3034 - val_loss: 616.9866 - val_mae: 564.7167\n",
      "Epoch 41/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 600.6710 - mae: 548.6412 - val_loss: 603.1445 - val_mae: 551.2029\n",
      "Epoch 42/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 597.3839 - mae: 545.4919 - val_loss: 625.8136 - val_mae: 574.0346\n",
      "Epoch 43/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 590.8188 - mae: 539.0225 - val_loss: 586.1094 - val_mae: 534.3625\n",
      "Epoch 44/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 592.9876 - mae: 541.3211 - val_loss: 590.3303 - val_mae: 538.6975\n",
      "Epoch 45/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 589.5617 - mae: 537.6573 - val_loss: 599.3915 - val_mae: 547.7440\n",
      "Epoch 46/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 596.6063 - mae: 545.0002 - val_loss: 579.8935 - val_mae: 528.5566\n",
      "Epoch 47/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 586.4815 - mae: 535.1077 - val_loss: 587.0662 - val_mae: 535.5308\n",
      "Epoch 48/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 581.3523 - mae: 529.8740 - val_loss: 589.6293 - val_mae: 538.3492\n",
      "Epoch 49/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 582.9739 - mae: 531.6719 - val_loss: 575.1695 - val_mae: 524.0975\n",
      "Epoch 50/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 583.0189 - mae: 532.0117 - val_loss: 585.9871 - val_mae: 534.9913\n",
      "Epoch 51/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 582.1381 - mae: 531.2545 - val_loss: 622.8256 - val_mae: 572.1631\n",
      "Epoch 52/500\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 590.5488 - mae: 539.6785 - val_loss: 578.0380 - val_mae: 527.2801\n",
      "Epoch 53/500\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 575.0555 - mae: 524.3000 - val_loss: 593.1796 - val_mae: 542.2029\n",
      "Epoch 54/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 577.1798 - mae: 526.4366 - val_loss: 574.7950 - val_mae: 524.2769\n",
      "Epoch 55/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 576.0472 - mae: 525.4090 - val_loss: 570.6397 - val_mae: 520.1628\n",
      "Epoch 56/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 574.0956 - mae: 523.6287 - val_loss: 609.2730 - val_mae: 558.7805\n",
      "Epoch 57/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 578.0791 - mae: 527.6995 - val_loss: 590.6729 - val_mae: 540.2831\n",
      "Epoch 58/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 569.6718 - mae: 519.4156 - val_loss: 618.1849 - val_mae: 567.8904\n",
      "Epoch 59/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 574.2139 - mae: 523.9150 - val_loss: 571.6587 - val_mae: 521.6132\n",
      "Epoch 60/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 571.1695 - mae: 521.2005 - val_loss: 614.7538 - val_mae: 564.9301\n",
      "Epoch 1/500\n",
      "  2/235 [..............................] - ETA: 11s - loss: 6173.5361 - mae: 6160.6045WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0138s vs `on_train_batch_end` time: 0.0817s). Check your callbacks.\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 3274.2148 - mae: 3255.2815 - val_loss: 1338.5304 - val_mae: 1303.9265\n",
      "Epoch 2/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 1184.9811 - mae: 1145.4379 - val_loss: 1083.7523 - val_mae: 1041.2327\n",
      "Epoch 3/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 1039.4919 - mae: 995.8578 - val_loss: 973.3637 - val_mae: 928.3223\n",
      "Epoch 4/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 947.4439 - mae: 901.3469 - val_loss: 890.0956 - val_mae: 843.9160\n",
      "Epoch 5/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 895.1520 - mae: 848.5720 - val_loss: 845.4594 - val_mae: 798.2349\n",
      "Epoch 6/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 853.5944 - mae: 806.4390 - val_loss: 821.1801 - val_mae: 774.1808\n",
      "Epoch 7/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 822.4409 - mae: 775.2292 - val_loss: 787.2844 - val_mae: 739.4019\n",
      "Epoch 8/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 794.5833 - mae: 746.7994 - val_loss: 759.1443 - val_mae: 710.8256\n",
      "Epoch 9/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 772.7222 - mae: 724.3337 - val_loss: 738.5560 - val_mae: 689.8979\n",
      "Epoch 10/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 751.0966 - mae: 702.0541 - val_loss: 728.3769 - val_mae: 678.8314\n",
      "Epoch 11/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 744.3761 - mae: 694.5951 - val_loss: 706.2883 - val_mae: 656.2932\n",
      "Epoch 12/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 724.3394 - mae: 673.9211 - val_loss: 705.5021 - val_mae: 654.6252\n",
      "Epoch 13/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 716.1390 - mae: 665.1369 - val_loss: 696.4834 - val_mae: 645.3239\n",
      "Epoch 14/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 710.6119 - mae: 659.3636 - val_loss: 680.4136 - val_mae: 628.9222\n",
      "Epoch 15/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 699.4568 - mae: 647.7016 - val_loss: 675.4242 - val_mae: 623.7054\n",
      "Epoch 16/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 696.4420 - mae: 644.4914 - val_loss: 678.3687 - val_mae: 626.2847\n",
      "Epoch 17/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 683.3240 - mae: 631.1446 - val_loss: 654.7714 - val_mae: 602.3408\n",
      "Epoch 18/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 676.4121 - mae: 624.0353 - val_loss: 667.7863 - val_mae: 615.4092\n",
      "Epoch 19/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 674.0336 - mae: 621.4773 - val_loss: 646.1928 - val_mae: 593.6617\n",
      "Epoch 20/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 664.2484 - mae: 611.6707 - val_loss: 646.5085 - val_mae: 593.9860\n",
      "Epoch 21/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 663.8182 - mae: 611.2896 - val_loss: 642.9667 - val_mae: 590.4625\n",
      "Epoch 22/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 658.5857 - mae: 606.0391 - val_loss: 698.7868 - val_mae: 645.9158\n",
      "Epoch 23/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 657.5679 - mae: 604.9614 - val_loss: 681.6047 - val_mae: 629.1934\n",
      "Epoch 24/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 651.0121 - mae: 598.4410 - val_loss: 624.6232 - val_mae: 572.1082\n",
      "Epoch 25/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 646.5966 - mae: 594.2022 - val_loss: 629.1495 - val_mae: 576.8482\n",
      "Epoch 26/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 645.5629 - mae: 593.2592 - val_loss: 617.7214 - val_mae: 565.4277\n",
      "Epoch 27/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 639.9344 - mae: 587.7798 - val_loss: 693.9139 - val_mae: 641.8536\n",
      "Epoch 28/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 638.3761 - mae: 586.2761 - val_loss: 636.4191 - val_mae: 584.4774\n",
      "Epoch 29/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 634.2906 - mae: 582.4573 - val_loss: 613.0999 - val_mae: 561.3601\n",
      "Epoch 30/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 631.4070 - mae: 579.5229 - val_loss: 609.6912 - val_mae: 557.7867\n",
      "Epoch 31/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 630.8288 - mae: 579.0287 - val_loss: 636.8486 - val_mae: 585.1989\n",
      "Epoch 32/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 627.0765 - mae: 575.5181 - val_loss: 615.4854 - val_mae: 563.6028\n",
      "Epoch 33/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 622.8878 - mae: 571.0995 - val_loss: 634.0784 - val_mae: 582.3908\n",
      "Epoch 34/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 624.6260 - mae: 573.0033 - val_loss: 592.8552 - val_mae: 541.2967\n",
      "Epoch 35/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 619.1023 - mae: 567.5549 - val_loss: 591.1376 - val_mae: 539.6202\n",
      "Epoch 36/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 614.1571 - mae: 562.5727 - val_loss: 602.8708 - val_mae: 551.2505\n",
      "Epoch 37/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 609.2505 - mae: 557.5093 - val_loss: 595.3874 - val_mae: 543.6230\n",
      "Epoch 38/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 615.1329 - mae: 563.2417 - val_loss: 583.7800 - val_mae: 531.8545\n",
      "Epoch 39/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 598.8633 - mae: 546.8627 - val_loss: 598.1617 - val_mae: 546.1447\n",
      "Epoch 40/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 601.0707 - mae: 548.9881 - val_loss: 582.4027 - val_mae: 530.2338\n",
      "Epoch 41/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 601.4325 - mae: 549.0915 - val_loss: 589.7595 - val_mae: 537.5200\n",
      "Epoch 42/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 599.4694 - mae: 547.2964 - val_loss: 579.4799 - val_mae: 527.0832\n",
      "Epoch 43/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 593.1912 - mae: 540.8535 - val_loss: 573.6930 - val_mae: 521.3145\n",
      "Epoch 44/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 596.7827 - mae: 544.4360 - val_loss: 608.2054 - val_mae: 555.9224\n",
      "Epoch 45/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 589.6156 - mae: 537.2730 - val_loss: 573.0178 - val_mae: 520.7599\n",
      "Epoch 46/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 590.8456 - mae: 538.5269 - val_loss: 565.4210 - val_mae: 512.9890\n",
      "Epoch 47/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 590.1102 - mae: 537.6770 - val_loss: 587.9362 - val_mae: 535.4554\n",
      "Epoch 48/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 584.9977 - mae: 532.7183 - val_loss: 569.3359 - val_mae: 516.9588\n",
      "Epoch 49/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 584.4263 - mae: 531.9946 - val_loss: 564.4705 - val_mae: 512.1740\n",
      "Epoch 50/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 579.8701 - mae: 527.4850 - val_loss: 563.7790 - val_mae: 511.4288\n",
      "Epoch 51/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 585.5897 - mae: 533.3558 - val_loss: 597.2115 - val_mae: 544.9066\n",
      "Epoch 52/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 583.6735 - mae: 531.4236 - val_loss: 584.2466 - val_mae: 532.1804\n",
      "Epoch 53/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 584.6667 - mae: 532.6987 - val_loss: 572.0071 - val_mae: 519.9735\n",
      "Epoch 54/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 577.3172 - mae: 525.2031 - val_loss: 594.0108 - val_mae: 541.9520\n",
      "Epoch 55/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 578.7200 - mae: 526.7299 - val_loss: 557.6875 - val_mae: 505.7800\n",
      "Epoch 56/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 591.8085 - mae: 539.9268 - val_loss: 578.2289 - val_mae: 526.6547\n",
      "Epoch 57/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 575.2006 - mae: 523.5739 - val_loss: 574.3340 - val_mae: 522.6014\n",
      "Epoch 58/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 573.6706 - mae: 521.9285 - val_loss: 566.2212 - val_mae: 514.5416\n",
      "Epoch 59/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 575.2491 - mae: 523.7764 - val_loss: 592.5930 - val_mae: 540.8932\n",
      "Epoch 60/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 573.0065 - mae: 521.5188 - val_loss: 556.3644 - val_mae: 504.9349\n",
      "Epoch 61/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 573.0022 - mae: 521.5766 - val_loss: 569.5750 - val_mae: 518.2461\n",
      "Epoch 62/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 575.7855 - mae: 524.3802 - val_loss: 588.2644 - val_mae: 536.9329\n",
      "Epoch 63/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 567.5597 - mae: 516.3064 - val_loss: 630.9055 - val_mae: 579.5287\n",
      "Epoch 64/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 572.0751 - mae: 520.9118 - val_loss: 582.0998 - val_mae: 531.1522\n",
      "Epoch 65/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 572.1805 - mae: 521.1218 - val_loss: 565.4761 - val_mae: 514.7202\n",
      "Epoch 1/500\n",
      "  2/235 [..............................] - ETA: 9s - loss: 5725.0918 - mae: 5712.0962WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0095s vs `on_train_batch_end` time: 0.0694s). Check your callbacks.\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 3295.3938 - mae: 3277.5598 - val_loss: 1336.1437 - val_mae: 1303.2273\n",
      "Epoch 2/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 1191.1394 - mae: 1153.8978 - val_loss: 1089.5620 - val_mae: 1049.4500\n",
      "Epoch 3/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 1041.5684 - mae: 999.5541 - val_loss: 972.5475 - val_mae: 929.4442\n",
      "Epoch 4/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 944.9874 - mae: 900.9699 - val_loss: 896.9522 - val_mae: 852.0023\n",
      "Epoch 5/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 890.3829 - mae: 845.2797 - val_loss: 851.6912 - val_mae: 806.0078\n",
      "Epoch 6/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 851.3101 - mae: 805.4257 - val_loss: 831.6267 - val_mae: 785.7782\n",
      "Epoch 7/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 815.7327 - mae: 769.6952 - val_loss: 786.2623 - val_mae: 739.9507\n",
      "Epoch 8/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 789.6011 - mae: 743.0577 - val_loss: 775.0187 - val_mae: 728.1512\n",
      "Epoch 9/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 767.8666 - mae: 720.5712 - val_loss: 786.7312 - val_mae: 738.8850\n",
      "Epoch 10/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 756.5444 - mae: 708.2557 - val_loss: 737.5721 - val_mae: 688.9277\n",
      "Epoch 11/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 734.6371 - mae: 685.8020 - val_loss: 726.1697 - val_mae: 677.1508\n",
      "Epoch 12/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 727.1983 - mae: 677.7820 - val_loss: 716.3814 - val_mae: 666.8923\n",
      "Epoch 13/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 708.6323 - mae: 658.8129 - val_loss: 703.9063 - val_mae: 653.7787\n",
      "Epoch 14/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 707.6165 - mae: 657.2303 - val_loss: 696.5298 - val_mae: 646.1133\n",
      "Epoch 15/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 694.7103 - mae: 643.9332 - val_loss: 683.5140 - val_mae: 632.7233\n",
      "Epoch 16/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 692.2285 - mae: 641.2954 - val_loss: 668.4581 - val_mae: 617.2507\n",
      "Epoch 17/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 680.0884 - mae: 628.6243 - val_loss: 680.1876 - val_mae: 628.6500\n",
      "Epoch 18/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 673.7581 - mae: 622.2211 - val_loss: 667.7393 - val_mae: 615.7921\n",
      "Epoch 19/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 667.6544 - mae: 615.6624 - val_loss: 666.7731 - val_mae: 614.7941\n",
      "Epoch 20/500\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 667.7510 - mae: 615.7566 - val_loss: 646.3767 - val_mae: 594.1574\n",
      "Epoch 21/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 662.4633 - mae: 610.3704 - val_loss: 643.6288 - val_mae: 591.4986\n",
      "Epoch 22/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 654.5312 - mae: 602.2982 - val_loss: 646.2169 - val_mae: 593.9282\n",
      "Epoch 23/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 649.7233 - mae: 597.3710 - val_loss: 644.6976 - val_mae: 592.1919\n",
      "Epoch 24/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 650.9570 - mae: 598.5881 - val_loss: 675.6437 - val_mae: 623.2104\n",
      "Epoch 25/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 646.3463 - mae: 593.9069 - val_loss: 627.3547 - val_mae: 575.0696\n",
      "Epoch 26/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 636.5140 - mae: 584.1236 - val_loss: 621.4373 - val_mae: 569.2349\n",
      "Epoch 27/500\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 639.5726 - mae: 587.2692 - val_loss: 657.5096 - val_mae: 604.9900\n",
      "Epoch 28/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 636.2036 - mae: 583.7342 - val_loss: 621.5599 - val_mae: 569.0231\n",
      "Epoch 29/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 629.7408 - mae: 577.2899 - val_loss: 611.1713 - val_mae: 558.9394\n",
      "Epoch 30/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 632.4146 - mae: 580.1643 - val_loss: 607.4536 - val_mae: 555.0609\n",
      "Epoch 31/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 626.3475 - mae: 574.0333 - val_loss: 628.5851 - val_mae: 576.1851\n",
      "Epoch 32/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 623.0838 - mae: 570.6242 - val_loss: 655.7493 - val_mae: 603.4406\n",
      "Epoch 33/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 620.6682 - mae: 568.2252 - val_loss: 664.8486 - val_mae: 612.2780\n",
      "Epoch 34/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 616.2139 - mae: 563.6448 - val_loss: 613.5556 - val_mae: 561.2538\n",
      "Epoch 35/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 615.3540 - mae: 562.9661 - val_loss: 618.9128 - val_mae: 566.6100\n",
      "Epoch 1/500\n",
      "  2/235 [..............................] - ETA: 11s - loss: 5477.0625 - mae: 5464.1338WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0132s vs `on_train_batch_end` time: 0.0823s). Check your callbacks.\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 3430.6265 - mae: 3412.4470 - val_loss: 1364.8998 - val_mae: 1329.4829\n",
      "Epoch 2/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 1181.6460 - mae: 1141.0070 - val_loss: 1131.1949 - val_mae: 1087.6659\n",
      "Epoch 3/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 1041.3811 - mae: 996.5467 - val_loss: 1011.3513 - val_mae: 966.0800\n",
      "Epoch 4/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 947.9752 - mae: 901.6743 - val_loss: 928.4333 - val_mae: 881.5334\n",
      "Epoch 5/500\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 892.3853 - mae: 845.3234 - val_loss: 891.9221 - val_mae: 844.5050\n",
      "Epoch 6/500\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 850.7421 - mae: 803.4614 - val_loss: 859.9909 - val_mae: 813.1440\n",
      "Epoch 7/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 816.0327 - mae: 768.9931 - val_loss: 821.1134 - val_mae: 773.7318\n",
      "Epoch 8/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 790.0590 - mae: 742.3279 - val_loss: 790.0917 - val_mae: 742.1769\n",
      "Epoch 9/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 775.4287 - mae: 727.1083 - val_loss: 775.2485 - val_mae: 726.7953\n",
      "Epoch 10/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 755.0314 - mae: 706.2750 - val_loss: 760.2219 - val_mae: 710.9957\n",
      "Epoch 11/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 745.6011 - mae: 695.9160 - val_loss: 798.8890 - val_mae: 748.8241\n",
      "Epoch 12/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 727.2758 - mae: 677.0309 - val_loss: 764.2133 - val_mae: 713.9276\n",
      "Epoch 13/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 715.2496 - mae: 664.5351 - val_loss: 731.7385 - val_mae: 680.9000\n",
      "Epoch 14/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 706.7088 - mae: 655.7753 - val_loss: 710.4827 - val_mae: 659.0164\n",
      "Epoch 15/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 696.0594 - mae: 644.6133 - val_loss: 704.0551 - val_mae: 652.4065\n",
      "Epoch 16/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 695.4220 - mae: 643.6610 - val_loss: 714.3292 - val_mae: 662.6801\n",
      "Epoch 17/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 685.3723 - mae: 633.4773 - val_loss: 686.5903 - val_mae: 634.7429\n",
      "Epoch 18/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 674.0889 - mae: 621.9802 - val_loss: 721.2233 - val_mae: 669.2938\n",
      "Epoch 19/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 672.8642 - mae: 620.5813 - val_loss: 671.3035 - val_mae: 619.0637\n",
      "Epoch 20/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 667.0383 - mae: 614.8554 - val_loss: 671.5438 - val_mae: 619.5218\n",
      "Epoch 21/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 666.0318 - mae: 613.8241 - val_loss: 660.6469 - val_mae: 608.2176\n",
      "Epoch 22/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 653.4344 - mae: 601.1102 - val_loss: 656.4285 - val_mae: 604.2684\n",
      "Epoch 23/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 651.5819 - mae: 599.1706 - val_loss: 659.0624 - val_mae: 606.6977\n",
      "Epoch 24/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 646.0048 - mae: 593.8268 - val_loss: 666.0443 - val_mae: 614.1111\n",
      "Epoch 25/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 643.2867 - mae: 591.4836 - val_loss: 646.6376 - val_mae: 594.8462\n",
      "Epoch 26/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 639.5688 - mae: 587.8056 - val_loss: 644.4438 - val_mae: 592.7680\n",
      "Epoch 27/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 637.7859 - mae: 586.2359 - val_loss: 663.4566 - val_mae: 611.9177\n",
      "Epoch 28/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 631.8322 - mae: 580.4587 - val_loss: 652.0142 - val_mae: 600.6672\n",
      "Epoch 29/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 638.3676 - mae: 587.1162 - val_loss: 633.1879 - val_mae: 582.2456\n",
      "Epoch 30/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 627.9323 - mae: 576.9012 - val_loss: 650.9323 - val_mae: 599.8871\n",
      "Epoch 31/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 626.1327 - mae: 575.2257 - val_loss: 626.8726 - val_mae: 575.9222\n",
      "Epoch 32/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 625.5692 - mae: 574.6639 - val_loss: 641.9984 - val_mae: 591.1959\n",
      "Epoch 33/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 622.1743 - mae: 571.3783 - val_loss: 665.5786 - val_mae: 614.6688\n",
      "Epoch 34/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 615.7379 - mae: 564.9005 - val_loss: 619.8239 - val_mae: 568.9259\n",
      "Epoch 35/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 616.8263 - mae: 566.0545 - val_loss: 622.6714 - val_mae: 572.0411\n",
      "Epoch 36/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 613.8728 - mae: 563.2047 - val_loss: 644.6645 - val_mae: 594.0244\n",
      "Epoch 37/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 606.0939 - mae: 555.4990 - val_loss: 631.4246 - val_mae: 580.5443\n",
      "Epoch 38/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 610.4962 - mae: 559.6970 - val_loss: 718.8940 - val_mae: 668.1927\n",
      "Epoch 39/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 607.5309 - mae: 557.0126 - val_loss: 611.7261 - val_mae: 560.9963\n",
      "Epoch 40/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 602.1162 - mae: 551.5732 - val_loss: 641.0518 - val_mae: 590.4003\n",
      "Epoch 41/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 606.5363 - mae: 555.9888 - val_loss: 601.7827 - val_mae: 551.4059\n",
      "Epoch 42/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 597.3602 - mae: 547.0303 - val_loss: 604.9227 - val_mae: 554.4109\n",
      "Epoch 43/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 594.1578 - mae: 543.7983 - val_loss: 603.1511 - val_mae: 552.7382\n",
      "Epoch 44/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 593.0055 - mae: 542.6241 - val_loss: 599.6562 - val_mae: 549.4461\n",
      "Epoch 45/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 597.4154 - mae: 547.2044 - val_loss: 629.2696 - val_mae: 579.0176\n",
      "Epoch 46/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 592.9621 - mae: 542.8180 - val_loss: 616.8263 - val_mae: 566.6371\n",
      "Epoch 47/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 596.0563 - mae: 545.8615 - val_loss: 635.7138 - val_mae: 585.4926\n",
      "Epoch 48/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 587.4674 - mae: 537.3874 - val_loss: 594.0016 - val_mae: 544.0442\n",
      "Epoch 49/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 587.3738 - mae: 537.3241 - val_loss: 590.9499 - val_mae: 541.0756\n",
      "Epoch 50/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 585.3932 - mae: 535.3032 - val_loss: 590.1965 - val_mae: 540.2093\n",
      "Epoch 51/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 589.6602 - mae: 539.6979 - val_loss: 610.9442 - val_mae: 561.0175\n",
      "Epoch 52/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 583.5729 - mae: 533.5898 - val_loss: 680.9728 - val_mae: 631.0436\n",
      "Epoch 53/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 584.6599 - mae: 534.6738 - val_loss: 589.7371 - val_mae: 539.6443\n",
      "Epoch 54/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 580.1609 - mae: 530.2037 - val_loss: 583.6946 - val_mae: 533.8139\n",
      "Epoch 55/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 578.0174 - mae: 528.0161 - val_loss: 586.0151 - val_mae: 536.0853\n",
      "Epoch 56/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 582.1336 - mae: 532.2708 - val_loss: 626.3508 - val_mae: 576.4168\n",
      "Epoch 57/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 576.0356 - mae: 526.1724 - val_loss: 601.7509 - val_mae: 552.0470\n",
      "Epoch 58/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 583.2861 - mae: 533.5649 - val_loss: 675.2069 - val_mae: 625.6052\n",
      "Epoch 59/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 579.1897 - mae: 529.5854 - val_loss: 600.4777 - val_mae: 550.9689\n",
      "Epoch 1/500\n",
      "  2/235 [..............................] - ETA: 10s - loss: 6013.2192 - mae: 6000.2793WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0146s vs `on_train_batch_end` time: 0.0795s). Check your callbacks.\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 3333.1426 - mae: 3315.7224 - val_loss: 1401.4131 - val_mae: 1369.8542\n",
      "Epoch 2/500\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 1217.4913 - mae: 1180.2338 - val_loss: 1115.5287 - val_mae: 1075.0259\n",
      "Epoch 3/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 1057.9932 - mae: 1016.0331 - val_loss: 998.5881 - val_mae: 955.0998\n",
      "Epoch 4/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 958.6722 - mae: 914.0580 - val_loss: 935.5361 - val_mae: 889.9750\n",
      "Epoch 5/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 905.0419 - mae: 858.7908 - val_loss: 871.0964 - val_mae: 824.1682\n",
      "Epoch 6/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 862.3495 - mae: 815.1656 - val_loss: 840.5120 - val_mae: 793.0160\n",
      "Epoch 7/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 830.4342 - mae: 782.9286 - val_loss: 812.3570 - val_mae: 764.4038\n",
      "Epoch 8/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 803.7733 - mae: 755.5242 - val_loss: 805.8458 - val_mae: 757.4318\n",
      "Epoch 9/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 782.2384 - mae: 733.6099 - val_loss: 779.6506 - val_mae: 730.9723\n",
      "Epoch 10/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 766.5440 - mae: 717.6100 - val_loss: 763.6232 - val_mae: 714.0875\n",
      "Epoch 11/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 750.8289 - mae: 701.0174 - val_loss: 758.0677 - val_mae: 708.0787\n",
      "Epoch 12/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 740.3883 - mae: 690.3176 - val_loss: 809.8577 - val_mae: 759.4800\n",
      "Epoch 13/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 735.3994 - mae: 684.7148 - val_loss: 752.7722 - val_mae: 702.2548\n",
      "Epoch 14/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 735.7997 - mae: 685.2297 - val_loss: 732.4929 - val_mae: 681.5333\n",
      "Epoch 15/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 717.7257 - mae: 666.6500 - val_loss: 717.5167 - val_mae: 666.3687\n",
      "Epoch 16/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 714.1132 - mae: 662.9684 - val_loss: 713.8277 - val_mae: 662.6805\n",
      "Epoch 17/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 712.2336 - mae: 661.1746 - val_loss: 707.9737 - val_mae: 657.0147\n",
      "Epoch 18/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 701.3831 - mae: 650.2725 - val_loss: 702.2371 - val_mae: 651.1590\n",
      "Epoch 19/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 700.9552 - mae: 649.8676 - val_loss: 704.2487 - val_mae: 652.9599\n",
      "Epoch 20/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 691.9277 - mae: 640.7706 - val_loss: 685.2451 - val_mae: 633.9362\n",
      "Epoch 21/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 681.4050 - mae: 630.1508 - val_loss: 706.4994 - val_mae: 655.1166\n",
      "Epoch 22/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 678.7111 - mae: 627.4579 - val_loss: 679.3970 - val_mae: 628.1952\n",
      "Epoch 23/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 675.9521 - mae: 624.8254 - val_loss: 671.6948 - val_mae: 620.7309\n",
      "Epoch 24/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 667.0726 - mae: 615.9301 - val_loss: 680.1887 - val_mae: 628.9962\n",
      "Epoch 25/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 662.0056 - mae: 611.0854 - val_loss: 664.4928 - val_mae: 613.4611\n",
      "Epoch 26/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 657.8170 - mae: 606.7726 - val_loss: 655.0594 - val_mae: 604.4438\n",
      "Epoch 27/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 657.7471 - mae: 607.1672 - val_loss: 660.1155 - val_mae: 609.6502\n",
      "Epoch 28/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 647.3097 - mae: 597.0566 - val_loss: 651.2719 - val_mae: 600.8774\n",
      "Epoch 29/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 653.1913 - mae: 602.9132 - val_loss: 649.5928 - val_mae: 599.6349\n",
      "Epoch 30/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 641.2449 - mae: 591.3524 - val_loss: 663.1208 - val_mae: 613.3582\n",
      "Epoch 31/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 641.8438 - mae: 592.2576 - val_loss: 640.7254 - val_mae: 590.9748\n",
      "Epoch 32/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 637.4726 - mae: 588.0275 - val_loss: 637.7366 - val_mae: 588.4023\n",
      "Epoch 33/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 636.4878 - mae: 587.2517 - val_loss: 631.5581 - val_mae: 582.3357\n",
      "Epoch 34/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 626.6017 - mae: 577.3259 - val_loss: 632.2573 - val_mae: 582.9304\n",
      "Epoch 35/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 620.9081 - mae: 571.7607 - val_loss: 698.0900 - val_mae: 648.9121\n",
      "Epoch 36/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 622.0508 - mae: 572.9595 - val_loss: 643.5124 - val_mae: 594.5131\n",
      "Epoch 37/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 612.4965 - mae: 563.4511 - val_loss: 637.1218 - val_mae: 587.9576\n",
      "Epoch 38/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 608.1241 - mae: 558.9506 - val_loss: 612.4539 - val_mae: 563.1391\n",
      "Epoch 39/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 606.7148 - mae: 557.4747 - val_loss: 612.0433 - val_mae: 562.7690\n",
      "Epoch 40/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 614.8724 - mae: 565.7019 - val_loss: 631.1258 - val_mae: 582.0244\n",
      "Epoch 41/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 610.2025 - mae: 560.9320 - val_loss: 604.6257 - val_mae: 555.3657\n",
      "Epoch 42/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 602.1409 - mae: 552.8599 - val_loss: 604.4144 - val_mae: 555.1937\n",
      "Epoch 43/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 593.3795 - mae: 544.1277 - val_loss: 596.9965 - val_mae: 547.8024\n",
      "Epoch 44/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 590.8076 - mae: 541.5494 - val_loss: 616.2796 - val_mae: 567.0638\n",
      "Epoch 45/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 593.8251 - mae: 544.7626 - val_loss: 625.0357 - val_mae: 575.7546\n",
      "Epoch 46/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 588.6396 - mae: 539.3909 - val_loss: 607.5205 - val_mae: 558.3915\n",
      "Epoch 47/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 600.0726 - mae: 550.9398 - val_loss: 668.3151 - val_mae: 619.3893\n",
      "Epoch 48/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 584.6898 - mae: 535.7961 - val_loss: 588.5881 - val_mae: 539.7993\n",
      "Epoch 49/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 586.5613 - mae: 537.6680 - val_loss: 664.7745 - val_mae: 615.8078\n",
      "Epoch 50/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 580.7173 - mae: 531.6910 - val_loss: 601.8022 - val_mae: 552.7257\n",
      "Epoch 51/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 578.1048 - mae: 529.2220 - val_loss: 579.6927 - val_mae: 530.9323\n",
      "Epoch 52/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 581.7396 - mae: 532.9199 - val_loss: 581.4935 - val_mae: 532.8362\n",
      "Epoch 53/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 575.2877 - mae: 526.4554 - val_loss: 612.9785 - val_mae: 564.4412\n",
      "Epoch 54/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 577.5583 - mae: 528.8068 - val_loss: 578.4038 - val_mae: 529.5370\n",
      "Epoch 55/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 573.3384 - mae: 524.7106 - val_loss: 581.0521 - val_mae: 532.5640\n",
      "Epoch 56/500\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 571.7503 - mae: 523.2717 - val_loss: 574.9573 - val_mae: 526.5734\n",
      "Epoch 57/500\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 572.1574 - mae: 523.7188 - val_loss: 572.2430 - val_mae: 523.6896\n",
      "Epoch 58/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 571.0474 - mae: 522.6755 - val_loss: 596.4648 - val_mae: 548.3090\n",
      "Epoch 59/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 572.7770 - mae: 524.5352 - val_loss: 570.9200 - val_mae: 522.7654\n",
      "Epoch 60/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 563.9088 - mae: 515.8242 - val_loss: 617.4451 - val_mae: 569.2706\n",
      "Epoch 61/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 571.5048 - mae: 523.3961 - val_loss: 571.4519 - val_mae: 523.4304\n",
      "Epoch 62/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 563.7059 - mae: 515.8158 - val_loss: 591.6818 - val_mae: 543.7682\n",
      "Epoch 63/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 567.1381 - mae: 519.3693 - val_loss: 576.5057 - val_mae: 528.9412\n",
      "Epoch 64/500\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 563.7548 - mae: 516.1339 - val_loss: 583.3064 - val_mae: 535.9307\n"
     ]
    }
   ],
   "source": [
    "kfolder = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "zero = np.zeros(len(x))\n",
    "predictions = np.zeros(len(x_test))\n",
    "predictions_train = np.zeros(len(x))\n",
    "kfold = kfolder.split(x, y)\n",
    "\n",
    "for train_inx,valid_inx in kfold:\n",
    "    x_train = x[train_inx]\n",
    "    y_train = y[train_inx]\n",
    "    x_valid = x[valid_inx]\n",
    "    y_valid = y[valid_inx]\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02)))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02)))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02)))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02)))\n",
    "    model.add(tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.02)))\n",
    "    model.compile(loss='mean_absolute_error',optimizer=tf.keras.optimizers.Adam(),metrics=['mae'])\n",
    "    model.fit(x_train,y_train,batch_size =512,epochs=500,validation_data=(x_valid, y_valid), callbacks=callbacks)\n",
    "    zero[valid_inx] = model.predict(x_valid).reshape((model.predict(x_valid).shape[0],))\n",
    "    predictions += model.predict(x_test).reshape((model.predict(x_test).shape[0],)) / kfolder.n_splits\n",
    "    predictions_train += model.predict(x).reshape((model.predict(x).shape[0],)) / kfolder.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 546.63205492\n"
     ]
    }
   ],
   "source": [
    "print(\"mae: {:<8.8f}\".format(mean_absolute_error(zero, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1221.347366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>1905.472748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>8623.842407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>1245.840134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>1947.860931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SaleID        price\n",
       "0  200000  1221.347366\n",
       "1  200001  1905.472748\n",
       "2  200002  8623.842407\n",
       "3  200003  1245.840134\n",
       "4  200004  1947.860931"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试集输出\n",
    "predictions[predictions < 0] = 0\n",
    "res = pd.DataFrame()\n",
    "res['SaleID'] = test_data.SaleID\n",
    "res['price'] = predictions\n",
    "res.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
