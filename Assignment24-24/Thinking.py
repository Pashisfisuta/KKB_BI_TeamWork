1、新零售中的“人、货、场”分别指的是什么？

人：以人为本，构建用户画像（性别、年龄、人生阶段，兴趣爱好），无限逼近消费者内心需求，给用户推荐合适的产品
货：超越成本与价值。
在新零售时代，消费者不再满足于商品本身，而是更在意其背后的新内容。企业要尽可能提高与消费者“对话”的频次与质量，这样企业才能知道消费者想要什么。
场：指消费的场所/场景。体验与全渠道。
消费者身上普遍都打着社交化、本地化、移动化、个性化的标签，他们绝不会满足于一种或是几种消费渠道，而是崇尚在消费的各个阶段都能随时随地购物、娱乐和社交的综合消费体验，并希望无论是通过有形店铺还是无形店铺，甚至是其他媒介渠道，都能够获得一致性的购物体验与营销服务。



2、AIPL与传统的品牌资产评估有何区别？
在AIPL模型之前，“人群资产”是很难量化，我们只能定性说可口可乐的人群资产比元气森林的多。
AIPL模型（认知Awareness、兴趣Interest、购买Purchase、忠诚Loyalty）是把品牌在电商中的人群资产定量化的运营模型。



3、请列举一例生活工作中存在的帕累托法则
帕累托法则，又称二八定律，帕累托定律。
20/80的法则认为：原因和结果、投入和产出、努力和报酬之间存在着无法解释的不平衡，即：
多数（80%），只能造成少许的影响（20%）
少数（20%），造成主要的、重大的影响（80%）
一些公司对用户进行分析，就是基于帕累托法则来定的，即：80%的利润来自于20%的用户，会设立专门的部门为这20%的用户提供惊喜服务而成立的。



4、请简述GBDT与XGBoost的区别？
GBDT是一种常用的非线性模型，基于集成学习中的boosting思想，也就是每次迭代都在减少残差的梯度方向新建立一颗决策树，迭代多少次就会生成多少颗决策树。XGBoost是GBDT的工业版本。二者的区别：
XGBoost的损失函数，相比GBDT只用到一阶泰勒展开，XGBoost则用到了二阶泰勒展开，因此更加精确。
XGBoost将树模型的复杂度加入到正则项中，从而避免过拟合，泛化性能好；
XGBoost在寻找最佳分割点时，采用近似贪心算法，用来加速计算；
GBDT指的是梯度提升决策树算法。XGBoost不仅支持CART作为基分类器，还支持线性分类器，在使用线性分类器的时候可以使用L1，L2正则化；
GBDT没有设计对缺失值的处理，XGBoost能够学习出默认的节点分裂方向来处理缺失值；
GBDT每轮使用全部数据，XGBoost支持对数据进行采样。XGBoost将特征列排序后以block的形式存储在内存中，在后面的迭代中重复使用这个结构。在进行节点分裂时，计算每个特征的增益，选择增益最大的特征作为分割节点，各个特征的增益计算可以使用多线程并行。


5、如何处理神经网络中的过拟合问题？

过拟合是指在训练数据上达到了很好的效果，但在验证数据上模型的准确性将在到峰值后停滞或开始下降。
处理过拟合的方法如下：
1、获得更多的训练数据，比如数据增强

2、L1/L2正则化方法：神经网络中损失函数，可以增加一个额外的正则项（L1或L2）正则项看做是损失函数的惩罚项。
L1正则，权值向量w中各个元素的绝对值之和
L2正则，权值向量w中各个元素的平方和，然后再求平方根

3、Dropout层：
step1： 随机删除处于隐蔽层(Hidden Layer)的神经元，删除比例由人为设定。
step2：通过重复执行随机删除神经元，形成不同结构的神经网络后，取各个网络结果的均值，达到正则化的效果。
其优势在于节省时间，同时减少了神经元之间复杂的共适性。因为一个神经元不能依赖其他特定的神经元。因此，不得不去学习随机子集神经元间的鲁棒性的有用连接。
对于较复杂的算法和大型的数据来说是一个非常好的选择。

